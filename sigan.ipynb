{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a1321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import autokeras as ak\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417955b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux Assumed:\n"
     ]
    }
   ],
   "source": [
    "from pebble import ProcessPool\n",
    "from concurrent.futures import TimeoutError\n",
    "from multiprocessing import freeze_support\n",
    "import sys\n",
    "\n",
    "import traceback\n",
    "import timeit\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, RidgeClassifier, SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, CategoricalNB, ComplementNB, GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier, NearestCentroid\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.svm import SVR, LinearSVR, NuSVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import LassoLarsIC, GammaRegressor, TweedieRegressor, BayesianRidge, ARDRegression,  LinearRegression, Ridge, RidgeCV, SGDRegressor, ElasticNet, HuberRegressor, QuantileRegressor, RANSACRegressor, TheilSenRegressor, PoissonRegressor, PassiveAggressiveRegressor, OrthogonalMatchingPursuit\n",
    "from sklearn.neighbors import KNeighborsRegressor, RadiusNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.cross_decomposition import PLSRegression, PLSCanonical\n",
    "\n",
    "def format_time(seconds):\n",
    "    return time.strftime('%H:%M:%S', time.gmtime(seconds))\n",
    "\n",
    "def initializer(limit):\n",
    "    soft, hard = resource.getrlimit(resource.RLIMIT_AS)\n",
    "    resource.setrlimit(resource.RLIMIT_AS, (limit, hard))\n",
    "\n",
    "classifiers = {\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=0),\n",
    "    \"Bagging\": BaggingClassifier(n_estimators=10, random_state=0),\n",
    "    \"ExtraTrees (Gini)\": ExtraTreesClassifier(criterion=\"gini\", n_estimators=100, random_state=0),\n",
    "    \"ExtraTrees (Entropy)\": ExtraTreesClassifier(criterion=\"entropy\", n_estimators=100, random_state=0),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0),\n",
    "    \"RandomForest\": RandomForestClassifier(max_depth=2, random_state=0),\n",
    "    \"HistGradientBoosting\": HistGradientBoostingClassifier(),\n",
    "    \"GaussianProcess\": GaussianProcessClassifier(random_state=0),\n",
    "    \"PassiveAggressive\": PassiveAggressiveClassifier(max_iter=1000, random_state=0, tol=1e-3),\n",
    "    \"Ridge\": RidgeClassifier(),\n",
    "    \"SGDClassifier\": make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3)),\n",
    "    \"BernoulliNaiveBayes\": BernoulliNB(),\n",
    "    \"CategoricalNaiveBayes\": CategoricalNB(),\n",
    "    \"ComplementNaiveBayes\": ComplementNB(),\n",
    "    \"GaussianNaiveBayes\": GaussianNB(),\n",
    "    \"MultinomialNaiveBayes\": MultinomialNB(),\n",
    "    \"KNeighbors\": KNeighborsClassifier(n_neighbors=3),\n",
    "    \"RadiusNeighbors\": RadiusNeighborsClassifier(radius=1.0),\n",
    "    \"NearestCentroid\": NearestCentroid(),\n",
    "    \"MLP\": MLPClassifier(random_state=1, max_iter=300),\n",
    "    \"LabelPropagation\": LabelPropagation(),\n",
    "    \"LinearSVC\": make_pipeline(StandardScaler(), LinearSVC(random_state=0, tol=1e-5)),\n",
    "    \"NuSVC\": make_pipeline(StandardScaler(), NuSVC()),\n",
    "    \"SVC\": make_pipeline(StandardScaler(), SVC(gamma='auto')),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=0),\n",
    "    \"ExtraTree\": ExtraTreeClassifier(random_state=0)\n",
    "}\n",
    "\n",
    "def test_classifier(classifier_type, X_train, X_test, y_train, y_test): \n",
    "    try:\n",
    "        start_time = timeit.default_timer()\n",
    "        print(\"\\nClassifier\", classifier_type, \"...\")\n",
    "        clf = classifiers[classifier_type]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_predicted = clf.predict(X_test)\n",
    "        accuracy = metrics.accuracy_score(y_test, y_predicted)\n",
    "        print(\"\\nClassifier\", classifier_type, \"accuracy is\", accuracy)\n",
    "        stop_time = timeit.default_timer()\n",
    "        print(\"Classifier\", classifier_type, \"completed in\", format_time(stop_time-start_time))\n",
    "        return [classifier_type, accuracy]\n",
    "    except Exception: \n",
    "        print(\"\\nError for Classifier\", classifier_type)\n",
    "        traceback.print_exc()\n",
    "\n",
    "def test_classifiers(X_train, X_test, y_train, y_test):\n",
    "    result_queue = []\n",
    "    if (LINUX):\n",
    "        with ProcessPool(max_workers=POOL,initializer=initializer, initargs=(MAX_MEMORY,)) as pool:             \n",
    "            multiple_results = [(pool.schedule(test_classifier, args=(key, X_train, X_test, y_train, y_test), timeout=TIMEOUT_SECONDS), key) for key in classifiers]\n",
    "            for res in multiple_results:\n",
    "                try:\n",
    "                    tmp = res[0].result()\n",
    "                    if tmp is not None:\n",
    "                        result_queue.append(tmp)\n",
    "                except TimeoutError:\n",
    "                    print(\"\\nClassifier\", res[1], \"exceeded the time limit.\")\n",
    "                except MemoryError:\n",
    "                    print(\"\\nClassifier\", res[1], \"exceeded the memory limit.\")\n",
    "    else: \n",
    "        with ProcessPool(max_workers=POOL) as pool:             \n",
    "            multiple_results = [(pool.schedule(test_classifier, args=(key, X_train, X_test, y_train, y_test), timeout=TIMEOUT_SECONDS), key) for key in classifiers]\n",
    "            for res in multiple_results:\n",
    "                try:\n",
    "                    tmp = res[0].result()\n",
    "                    if tmp is not None:\n",
    "                        result_queue.append(tmp)\n",
    "                except TimeoutError:\n",
    "                    print(\"\\nClassifier\", res[1], \"exceeded the time limit.\")\n",
    "\n",
    "    accuracy = {}\n",
    "    for value in result_queue:\n",
    "        accuracy[value[0]] = value[1]\n",
    "    accuracy = {k: v for k, v in sorted(accuracy.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    print(\"Results: \\n\")\n",
    "    untested = set(classifiers.keys())\n",
    "    i = 1\n",
    "    for key in accuracy:\n",
    "        print(i, key, accuracy[key])\n",
    "        untested.remove(key)\n",
    "        i += 1\n",
    "    print(\"\\nUntested Classifiers:\", untested)\n",
    "\n",
    "regressors = {\n",
    "    \"AdaBoost (square)\" : AdaBoostRegressor(random_state=0, n_estimators=100, loss=\"square\"),\n",
    "    \"AdaBoost (linear)\" : AdaBoostRegressor(random_state=0, n_estimators=100, loss=\"linear\"),\n",
    "    \"Adaboost (exponential)\" : AdaBoostRegressor(random_state=0, n_estimators=100, loss=\"exponential\"),\n",
    "    \"Bagging\" : BaggingRegressor(n_estimators=10, random_state=0),\n",
    "    \"Bagging (svr)\": BaggingRegressor(base_estimator=SVR(), n_estimators=10, random_state=0),\n",
    "    \"ExtraTrees (abs err)\" : ExtraTreesRegressor(criterion = \"absolute_error\", n_estimators=100, random_state=0),\n",
    "    \"ExtraTrees (sq err)\" : ExtraTreesRegressor(criterion = \"squared_error\", n_estimators=100, random_state=0),\n",
    "    \"GradientBoosting (huber)\" : GradientBoostingRegressor(random_state=0,loss=\"huber\"),\n",
    "    \"GradientBoosting (sq err)\" : GradientBoostingRegressor(random_state=0,loss=\"squared_error\"),\n",
    "    \"GradientBoosting (abs err)\" : GradientBoostingRegressor(random_state=0,loss=\"absolute_error\"),\n",
    "    \"Random Forest (sq err)\" : RandomForestRegressor(max_depth=2, random_state=0,criterion=\"squared_error\"),\n",
    "    \"Random Forst (abs err)\" : RandomForestRegressor(max_depth=2, random_state=0,criterion=\"absolute_error\"),\n",
    "    \"Random Forest (poisson)\" : RandomForestRegressor(max_depth=2, random_state=0,criterion=\"poisson\"),\n",
    "    \"HistGradientBoosting (sq err)\" : HistGradientBoostingRegressor(loss=\"squared_error\"),\n",
    "    \"HistGradientBoosting (abs err)\" : HistGradientBoostingRegressor(loss=\"absolute_error\"),\n",
    "    \"HistGradientBoosting (poisson)\" : HistGradientBoostingRegressor(loss=\"poisson\"),\n",
    "    \"GaussianProcess\" : GaussianProcessRegressor(random_state=0),\n",
    "    \"Linear\" : LinearRegression(),\n",
    "    \"Ridge (Linear)\" : Ridge(),\n",
    "    \"RidgeCV\" : RidgeCV(),\n",
    "    \"SGDRegressor (elasticnet)\" : make_pipeline(StandardScaler(),SGDRegressor(max_iter=1000, tol=1e-3,penalty=\"elasticnet\")),\n",
    "    \"SGDRegressor (l2)\" : make_pipeline(StandardScaler(),SGDRegressor(max_iter=1000, tol=1e-3,penalty=\"l2\")),\n",
    "    \"SGDRegressor (l1)\" : make_pipeline(StandardScaler(),SGDRegressor(max_iter=1000, tol=1e-3,penalty=\"l1\")),\n",
    "    \"Elastic Net (random)\" : ElasticNet(random_state=0,selection=\"random\"),\n",
    "    \"Elastic Net (cyclic)\" : ElasticNet(random_state=0,selection=\"cyclic\"),\n",
    "    \"ARD\" : ARDRegression(),\n",
    "    \"BayesianRidge\" : BayesianRidge(),\n",
    "    \"Huber\" : HuberRegressor(),\n",
    "    \"Quantile (highs-ds)\" : QuantileRegressor(quantile=0.8, solver=\"highs-ds\"),\n",
    "    \"Quantile (highs-ipm)\" : QuantileRegressor(quantile=0.8, solver=\"highs-ipm\"),\n",
    "    \"Quantile (highs)\" : QuantileRegressor(quantile=0.8, solver=\"highs\"),\n",
    "    \"Quantile (interior-point)\" : QuantileRegressor(quantile=0.8, solver=\"interior-point\"),\n",
    "    \"Quantile (revised simplex)\" : QuantileRegressor(quantile=0.8, solver=\"revised simplex\"),\n",
    "    \"RANSAC\": RANSACRegressor(random_state=0),\n",
    "    \"TheilSenRegressor\" : TheilSenRegressor(random_state=0),\n",
    "    \"PoissonRegressor\" : PoissonRegressor(),\n",
    "    \"TweedieRegressor (auto)\" : TweedieRegressor(link=\"auto\"),\n",
    "    \"TweedieRegressor (identity)\" : TweedieRegressor(link=\"identity\"),\n",
    "    \"TweedieRegressor (log)\" : TweedieRegressor(link=\"log\"),\n",
    "    \"GammaRegressor\" : GammaRegressor(),\n",
    "    \"PassiveAggressiveRegressor (epsilon_insensitive)\" :  PassiveAggressiveRegressor(max_iter=100, random_state=0, tol=1e-3, loss=\"epsilon_insensitive\"),\n",
    "    \"PassiveAggressiveRegressor (squared_epsilon_insensitive)\" :  PassiveAggressiveRegressor(max_iter=100, random_state=0, tol=1e-3, loss=\"squared_epsilon_insensitive\"),\n",
    "    \"KNeighbors\" : KNeighborsRegressor(n_neighbors=3),\n",
    "    \"Radius Neighbors\" : RadiusNeighborsRegressor(radius=1.0),\n",
    "    \"MLP\" : MLPRegressor(random_state=1, max_iter=500),\n",
    "    \"DecisionTree\" : DecisionTreeRegressor(random_state=0),\n",
    "    \"Extra Tree\" : ExtraTreeRegressor(random_state=0),\n",
    "    \"Kernel Ridge\" : KernelRidge(alpha=1.0),\n",
    "    \"Linear SVR (epsilon_insensitive)\" : make_pipeline(StandardScaler(), LinearSVR(random_state=0, tol=1e-5, loss=\"epsilon_insensitive\")),\n",
    "    \"Linear SVR (squared_epsilon_insensitive)\" : make_pipeline(StandardScaler(), LinearSVR(random_state=0, tol=1e-5, loss=\"squared_epsilon_insensitive\")),\n",
    "    \"nuSVR\" : make_pipeline(StandardScaler(), NuSVR(C=1.0, nu=0.1)),\n",
    "    \"SVR\" : make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2)),\n",
    "    \"LassoLarsIC (bic)\" : LassoLarsIC(criterion='bic', normalize=False),\n",
    "    \"LassoLarsIC (aic)\" : LassoLarsIC(criterion='aic', normalize=False),\n",
    "    \"PLS\" : PLSRegression(n_components=2),\n",
    "    \"OrthogonalMatchingPursuit\" : OrthogonalMatchingPursuit(),\n",
    "    \"PLSCanonical\" : PLSCanonical(n_components=2)\n",
    "}\n",
    "\n",
    "def test_regressor(regressor_type, X_train, X_test, y_train, y_test): \n",
    "    try:\n",
    "        start_time = timeit.default_timer()\n",
    "        print(\"\\nRegressor\", regressor_type, \"...\")\n",
    "        reg = regressors[regressor_type]\n",
    "        reg.fit(X_train, y_train)\n",
    "        y_predicted = reg.predict(X_test)\n",
    "        accuracy = metrics.mean_absolute_error(y_test, y_predicted)\n",
    "        print(\"\\nRegressor\", regressor_type, \"accuracy is\", accuracy)\n",
    "        stop_time = timeit.default_timer()\n",
    "        print(\"Regressor\", regressor_type, \"completed in\", format_time(stop_time-start_time))\n",
    "        return [regressor_type, accuracy]\n",
    "    except Exception: \n",
    "        print(\"\\nError for Regressor\", regressor_type)\n",
    "        traceback.print_exc()\n",
    "\n",
    "def test_regressors(X_train, X_test, y_train, y_test,):\n",
    "    result_queue = []\n",
    "    if (LINUX):\n",
    "        with ProcessPool(max_workers=POOL,initializer=initializer, initargs=(MAX_MEMORY,)) as pool:             \n",
    "            multiple_results = [(pool.schedule(test_regressor, args=(key, X_train, X_test, y_train, y_test), timeout=TIMEOUT_SECONDS), key) for key in regressors]\n",
    "            for res in multiple_results:\n",
    "                try:\n",
    "                    tmp = res[0].result()\n",
    "                    if tmp is not None:\n",
    "                        result_queue.append(tmp)\n",
    "                except TimeoutError:\n",
    "                    print(\"\\nClassifier\", res[1], \"exceeded the time limit.\")\n",
    "                except MemoryError:\n",
    "                    print(\"\\nClassifier\", res[1], \"exceeded the memory limit.\")\n",
    "    else: \n",
    "        with ProcessPool(max_workers=POOL) as pool:             \n",
    "            multiple_results = [(pool.schedule(test_regressor, args=(key, X_train, X_test, y_train, y_test), timeout=TIMEOUT_SECONDS), key) for key in regressors]\n",
    "            for res in multiple_results:\n",
    "                try:\n",
    "                    tmp = res[0].result()\n",
    "                    if tmp is not None:\n",
    "                        result_queue.append(tmp)\n",
    "                except TimeoutError:\n",
    "                    print(\"\\nClassifier\", res[1], \"exceeded the time limit.\") \n",
    "\n",
    "    mae = {}\n",
    "    for value in result_queue:\n",
    "        mae[value[0]] = value[1]\n",
    "    mae = {k: v for k, v in sorted(mae.items(), key=lambda item: item[1], reverse=False)}\n",
    "\n",
    "    print(\"Results: \\n\")\n",
    "    untested = set(regressors.keys())\n",
    "    i = 1\n",
    "    for key in mae:\n",
    "        print(i, key, mae[key])\n",
    "        untested.remove(key)\n",
    "        i += 1\n",
    "    print(\"\\nUntested Regressors:\", untested)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TIMEOUT_SECONDS = 60 * 10\n",
    "    POOL = 4\n",
    "    MAX_MEMORY = 1572864\n",
    "    SILENT = False\n",
    "\n",
    "    if (\"win\" in sys.platform):\n",
    "        print(\"Windows Detected\")\n",
    "        freeze_support()\n",
    "        LINUX = False\n",
    "    else: \n",
    "        print(\"Linux Assumed:\")\n",
    "        import resource\n",
    "        LINUX = True\n",
    "    if SILENT:\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35f712c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final.csv',\n",
       " 'structured_data_regressor',\n",
       " 'submission.csv',\n",
       " 'train.csv',\n",
       " 'test.csv',\n",
       " '.ipynb_checkpoints',\n",
       " 'sigan.ipynb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf74636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index   feature 0  feature 1  feature 2  feature 3  feature 4  feature 5  \\\n",
      "0        0  2014-11-23        2.6        2.4        2.6        2.6       27.0   \n",
      "1        1  2014-01-24        0.0        0.0        0.0        0.0       25.2   \n",
      "2        2  2017-07-01        0.0        0.0        0.0        0.0       29.3   \n",
      "3        3  2015-09-29        0.0        0.0        0.0        0.0       28.2   \n",
      "4        4  2016-11-06        1.0        0.8        1.0        1.0       28.1   \n",
      "..     ...         ...        ...        ...        ...        ...        ...   \n",
      "895    895  2014-03-12        0.0        0.0        0.0        0.0       27.7   \n",
      "896    896  2016-02-06        2.6        1.2        1.2        1.2       28.0   \n",
      "897    897  2014-05-19       29.4       18.8       27.6       28.6       27.1   \n",
      "898    898  2017-04-07        3.6        1.2        1.8        2.8       27.7   \n",
      "899    899  2015-01-17        0.0        0.0        0.0        0.0       26.5   \n",
      "\n",
      "     feature 6  feature 7  feature 9  predict  \n",
      "0         33.0       25.6       36.0      5.5  \n",
      "1         28.3       23.0       35.3     12.6  \n",
      "2         32.6       26.9       28.8      6.5  \n",
      "3         31.7       24.9       26.3      5.7  \n",
      "4         31.7       25.0       28.1      8.6  \n",
      "..         ...        ...        ...      ...  \n",
      "895       33.4       24.7       36.7     13.1  \n",
      "896       31.4       26.1       44.6     14.8  \n",
      "897       30.2       22.7       43.9      6.3  \n",
      "898       33.0       23.9       48.6      8.3  \n",
      "899       30.9       23.5       37.1     14.1  \n",
      "\n",
      "[900 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "trainDf = pd.read_csv('/home/test/Desktop/Cyberthon/final/signal analysis/train.csv')\n",
    "print(trainDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e50d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index   feature 0  feature 1  feature 2  feature 3  feature 4  feature 5  \\\n",
      "0        0  2014-11-23        2.6        2.4        2.6        2.6       27.0   \n",
      "1        1  2014-01-24        0.0        0.0        0.0        0.0       25.2   \n",
      "2        2  2017-07-01        0.0        0.0        0.0        0.0       29.3   \n",
      "3        3  2015-09-29        0.0        0.0        0.0        0.0       28.2   \n",
      "4        4  2016-11-06        1.0        0.8        1.0        1.0       28.1   \n",
      "..     ...         ...        ...        ...        ...        ...        ...   \n",
      "895    895  2014-03-12        0.0        0.0        0.0        0.0       27.7   \n",
      "896    896  2016-02-06        2.6        1.2        1.2        1.2       28.0   \n",
      "897    897  2014-05-19       29.4       18.8       27.6       28.6       27.1   \n",
      "898    898  2017-04-07        3.6        1.2        1.8        2.8       27.7   \n",
      "899    899  2015-01-17        0.0        0.0        0.0        0.0       26.5   \n",
      "\n",
      "     feature 6  feature 7  feature 9  \n",
      "0         33.0       25.6       36.0  \n",
      "1         28.3       23.0       35.3  \n",
      "2         32.6       26.9       28.8  \n",
      "3         31.7       24.9       26.3  \n",
      "4         31.7       25.0       28.1  \n",
      "..         ...        ...        ...  \n",
      "895       33.4       24.7       36.7  \n",
      "896       31.4       26.1       44.6  \n",
      "897       30.2       22.7       43.9  \n",
      "898       33.0       23.9       48.6  \n",
      "899       30.9       23.5       37.1  \n",
      "\n",
      "[900 rows x 10 columns]\n",
      "0       5.5\n",
      "1      12.6\n",
      "2       6.5\n",
      "3       5.7\n",
      "4       8.6\n",
      "       ... \n",
      "895    13.1\n",
      "896    14.8\n",
      "897     6.3\n",
      "898     8.3\n",
      "899    14.1\n",
      "Name: predict, Length: 900, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y = trainDf[\"predict\"]\n",
    "X = trainDf.drop(\"predict\", axis = 1)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2855bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need feature engineering here (before the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c12b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX[\"feature 1\"] *= 10\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"year\"] = X[\"feature 0\"].str.slice(stop = 4)\n",
    "X[\"month\"] = X[\"feature 0\"].str.slice(start=5, stop=7)\n",
    "X[\"day\"] = X[\"feature 0\"].str.slice(start=8, stop=10)\n",
    "X = X.drop(\"feature 0\", axis=1)\n",
    "'''\n",
    "X[\"feature 1\"] *= 10\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64cf3cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfeatures = \\ndef make_mi_scores(X, y, discrete_features):\\n    mi_scores = mutual_info_regression(X, y, discrete_features= [\"year\", \"month\"])\\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\\n    mi_scores = mi_scores.sort_values(ascending=False)\\n    return mi_scores\\n\\nmi_scores = make_mi_scores(X, y, features)\\nmi_scores[::3]  # show a few features with their MI scores\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "features = \n",
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features= [\"year\", \"month\"])\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "mi_scores = make_mi_scores(X, y, features)\n",
    "mi_scores[::3]  # show a few features with their MI scores\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb95723",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=42)\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "781df30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_regressors(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53858590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.linear_model import QuantileRegressor\\n\\nmodel1 = QuantileRegressor()\\nmodel1.fit(X_train, y_train)\\ny_pred = model1.predict(X_test)\\n\\nmae = mean_absolute_error\\nprint(mae(y_test, y_pred))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "\n",
    "model1 = QuantileRegressor()\n",
    "model1.fit(X_train, y_train)\n",
    "y_pred = model1.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error\n",
    "print(mae(y_test, y_pred))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d45768f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41129058130228\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "model2 = ExtraTreesRegressor(random_state = 42)\n",
    "model2.fit(X_train, y_train)\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "\n",
    "mae = mean_absolute_error\n",
    "print(mae(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65e285f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.003553865575501\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model3 = GradientBoostingRegressor(random_state = 42)\n",
    "model3.fit(X_train, y_train)\n",
    "y_pred3 = model3.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error\n",
    "print(mae(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41bdb628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nreg = ak.StructuredDataRegressor(\\n    overwrite=True,\\n    max_trials=100,\\n)\\n\\nreg.fit(\\n    x=X, #replace with wtv features u want\\n    y=y, #label\\n    validation_split=0.15, #validation split\\n    epochs=100, #experiment with this, too much may cause overfitting\\n)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "reg = ak.StructuredDataRegressor(\n",
    "    overwrite=True,\n",
    "    max_trials=100,\n",
    ")\n",
    "\n",
    "reg.fit(\n",
    "    x=X, #replace with wtv features u want\n",
    "    y=y, #label\n",
    "    validation_split=0.15, #validation split\n",
    "    epochs=100, #experiment with this, too much may cause overfitting\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bed70218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>feature 0</th>\n",
       "      <th>feature 1</th>\n",
       "      <th>feature 2</th>\n",
       "      <th>feature 3</th>\n",
       "      <th>feature 4</th>\n",
       "      <th>feature 5</th>\n",
       "      <th>feature 6</th>\n",
       "      <th>feature 7</th>\n",
       "      <th>feature 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>900</td>\n",
       "      <td>2017-09-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.2</td>\n",
       "      <td>32.1</td>\n",
       "      <td>27.4</td>\n",
       "      <td>36.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>901</td>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>33.8</td>\n",
       "      <td>26.5</td>\n",
       "      <td>29.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>902</td>\n",
       "      <td>2015-02-04</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.1</td>\n",
       "      <td>27.1</td>\n",
       "      <td>23.1</td>\n",
       "      <td>34.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>903</td>\n",
       "      <td>2015-10-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>33.1</td>\n",
       "      <td>25.6</td>\n",
       "      <td>28.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>904</td>\n",
       "      <td>2014-01-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>28.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>41.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1064</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>28.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>34.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1065</td>\n",
       "      <td>2017-09-08</td>\n",
       "      <td>37.4</td>\n",
       "      <td>21.8</td>\n",
       "      <td>29.8</td>\n",
       "      <td>37.4</td>\n",
       "      <td>27.2</td>\n",
       "      <td>32.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>49.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1066</td>\n",
       "      <td>2014-05-09</td>\n",
       "      <td>21.8</td>\n",
       "      <td>17.2</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.6</td>\n",
       "      <td>28.1</td>\n",
       "      <td>32.2</td>\n",
       "      <td>25.8</td>\n",
       "      <td>37.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1067</td>\n",
       "      <td>2015-06-14</td>\n",
       "      <td>10.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>26.3</td>\n",
       "      <td>28.1</td>\n",
       "      <td>24.2</td>\n",
       "      <td>42.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1068</td>\n",
       "      <td>2015-05-08</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>28.3</td>\n",
       "      <td>31.4</td>\n",
       "      <td>26.5</td>\n",
       "      <td>34.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index   feature 0  feature 1  feature 2  feature 3  feature 4  feature 5  \\\n",
       "0      900  2017-09-03        0.0        0.0        0.0        0.0       29.2   \n",
       "1      901  2014-11-04        0.0        0.0        0.0        0.0       29.7   \n",
       "2      902  2015-02-04        7.0        5.2        6.4        7.0       25.1   \n",
       "3      903  2015-10-27        0.0        0.0        0.0        0.0       28.4   \n",
       "4      904  2014-01-17        0.0        0.0        0.0        0.0       25.6   \n",
       "..     ...         ...        ...        ...        ...        ...        ...   \n",
       "164   1064  2014-01-01        0.0        0.0        0.0        0.0       26.3   \n",
       "165   1065  2017-09-08       37.4       21.8       29.8       37.4       27.2   \n",
       "166   1066  2014-05-09       21.8       17.2       21.4       21.6       28.1   \n",
       "167   1067  2015-06-14       10.4        6.8        8.2       10.2       26.3   \n",
       "168   1068  2015-05-08        4.4        3.4        3.6        3.6       28.3   \n",
       "\n",
       "     feature 6  feature 7  feature 9  \n",
       "0         32.1       27.4       36.7  \n",
       "1         33.8       26.5       29.2  \n",
       "2         27.1       23.1       34.2  \n",
       "3         33.1       25.6       28.4  \n",
       "4         28.6       23.5       41.8  \n",
       "..         ...        ...        ...  \n",
       "164       28.8       24.3       34.2  \n",
       "165       32.4       23.5       49.7  \n",
       "166       32.2       25.8       37.8  \n",
       "167       28.1       24.2       42.8  \n",
       "168       31.4       26.5       34.2  \n",
       "\n",
       "[169 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDf = pd.read_csv('/home/test/Desktop/Cyberthon/final/signal analysis/test.csv')\n",
    "testDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f6dc6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  feature 1  feature 2  feature 3  feature 4  feature 5  feature 6  \\\n",
      "0      900        0.0        0.0        0.0        0.0       29.2       32.1   \n",
      "1      901        0.0        0.0        0.0        0.0       29.7       33.8   \n",
      "2      902        7.0        5.2        6.4        7.0       25.1       27.1   \n",
      "3      903        0.0        0.0        0.0        0.0       28.4       33.1   \n",
      "4      904        0.0        0.0        0.0        0.0       25.6       28.6   \n",
      "..     ...        ...        ...        ...        ...        ...        ...   \n",
      "164   1064        0.0        0.0        0.0        0.0       26.3       28.8   \n",
      "165   1065       37.4       21.8       29.8       37.4       27.2       32.4   \n",
      "166   1066       21.8       17.2       21.4       21.6       28.1       32.2   \n",
      "167   1067       10.4        6.8        8.2       10.2       26.3       28.1   \n",
      "168   1068        4.4        3.4        3.6        3.6       28.3       31.4   \n",
      "\n",
      "     feature 7  feature 9  year month day  \n",
      "0         27.4       36.7  2017    09  03  \n",
      "1         26.5       29.2  2014    11  04  \n",
      "2         23.1       34.2  2015    02  04  \n",
      "3         25.6       28.4  2015    10  27  \n",
      "4         23.5       41.8  2014    01  17  \n",
      "..         ...        ...   ...   ...  ..  \n",
      "164       24.3       34.2  2014    01  01  \n",
      "165       23.5       49.7  2017    09  08  \n",
      "166       25.8       37.8  2014    05  09  \n",
      "167       24.2       42.8  2015    06  14  \n",
      "168       26.5       34.2  2015    05  08  \n",
      "\n",
      "[169 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "testDf[\"year\"] = testDf[\"feature 0\"].str.slice(stop = 4)\n",
    "testDf[\"month\"] = testDf[\"feature 0\"].str.slice(start=5, stop=7)\n",
    "testDf[\"day\"] = testDf[\"feature 0\"].str.slice(start=8, stop=10)\n",
    "testDf = testDf.drop(\"feature 0\", axis=1)\n",
    "print(testDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2e4b102",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = model3.predict(testDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86c9d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_predictions = reg.predict(testDf[['feature 5', 'feature 6', 'feature 7', 'feature 9']])\n",
    "#change features to match earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22f0171f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.01629954  8.04020216  9.28543027  7.13420862 13.54772392 10.60152818\n",
      "  9.20555659  8.3158969   7.52029158  6.95039162  7.90185249  6.72481779\n",
      "  7.91073562 13.77847719  6.78043496 12.27733252  8.49587799  6.63096845\n",
      "  8.15050226 10.87954649  5.99867146  6.83312995  7.15260478 10.63439139\n",
      "  7.56026535 10.37568295  7.60930778  7.62181955 10.77370751  6.84694854\n",
      "  6.58402295  7.25710801  5.85966176  9.48176943  8.20493524  6.84158912\n",
      "  7.01416719 14.11755812  6.56235941  8.5284506   8.54496102  7.13187566\n",
      "  7.13640665  9.86537595  8.52398267  7.17304326  7.26979356  8.00779038\n",
      "  6.81401047 14.55602311  6.93268769  7.53531062  6.44340895  7.47208887\n",
      "  7.71595631  7.65851493  5.99407021 13.46541984  6.39410957  8.19588364\n",
      "  8.03712582 12.84117099  6.17867326  8.25710197  8.94855536 13.71404796\n",
      " 10.29409461  6.56140199  7.78748671  6.87958157  6.58862969 12.4773502\n",
      " 10.35402897  6.76775393  7.30774609  7.99598644  7.64085147  9.01843595\n",
      "  6.69790143  6.1427181   6.45461098  7.29994143  8.56709087 16.33319387\n",
      "  6.87213254  6.63865647  6.21472601 14.67213705  7.6613224  15.22021892\n",
      "  6.90773929  6.11851453  7.2997222   7.28648626 11.29445919  6.09253897\n",
      " 12.87037083 13.12130441  6.70674075 13.22120096 13.40691983  8.61581788\n",
      " 12.10319142  8.49429951  6.7571416   6.49696369  6.74555667  7.95293688\n",
      "  6.68554092 12.71004157  7.76150961  8.40972777  9.05546044  6.73470933\n",
      " 13.92763169  7.069813    9.46244834  7.95829648  6.9986976  13.41173502\n",
      "  6.52406374  7.74453985  7.84771992  7.34449358  9.81937705 14.86618035\n",
      "  6.60232238  9.67209052  6.88515546  7.73490209  6.56150087  7.64734368\n",
      "  6.51999207 12.23488172  6.90254903  6.9696435   6.98669749 13.13271631\n",
      "  6.45871116  6.40166797  9.69439765 11.04085645  8.7285097   8.59298392\n",
      " 10.49446642  6.8568779   6.16415552 11.52884801 14.05599811  6.7706636\n",
      "  7.57088395  7.27569401  6.78005062  7.22680427  6.64647384  7.71811105\n",
      "  6.67065687  6.59841441  6.6799169   7.46944289  7.23606544  7.17612994\n",
      "  6.04328085 10.17058891 12.25172069  6.4594818   6.94697326  6.74055137\n",
      "  6.89849857]\n"
     ]
    }
   ],
   "source": [
    "print(y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07b6e4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>900</td>\n",
       "      <td>???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>901</td>\n",
       "      <td>???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>902</td>\n",
       "      <td>???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>903</td>\n",
       "      <td>???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>904</td>\n",
       "      <td>???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1064</td>\n",
       "      <td>???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1065</td>\n",
       "      <td>???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1066</td>\n",
       "      <td>???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1067</td>\n",
       "      <td>???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1068</td>\n",
       "      <td>???</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index predict\n",
       "0      900     ???\n",
       "1      901     ???\n",
       "2      902     ???\n",
       "3      903     ???\n",
       "4      904     ???\n",
       "..     ...     ...\n",
       "164   1064     ???\n",
       "165   1065     ???\n",
       "166   1066     ???\n",
       "167   1067     ???\n",
       "168   1068     ???\n",
       "\n",
       "[169 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissionDf = pd.read_csv('/home/test/Desktop/Cyberthon/final/signal analysis/submission.csv')\n",
    "submissionDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ce49836",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissionDf.predict = y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4695ce69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>900</td>\n",
       "      <td>9.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>901</td>\n",
       "      <td>8.040202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>902</td>\n",
       "      <td>9.285430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>903</td>\n",
       "      <td>7.134209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>904</td>\n",
       "      <td>13.547724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1064</td>\n",
       "      <td>12.251721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1065</td>\n",
       "      <td>6.459482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1066</td>\n",
       "      <td>6.946973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1067</td>\n",
       "      <td>6.740551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1068</td>\n",
       "      <td>6.898499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index    predict\n",
       "0      900   9.016300\n",
       "1      901   8.040202\n",
       "2      902   9.285430\n",
       "3      903   7.134209\n",
       "4      904  13.547724\n",
       "..     ...        ...\n",
       "164   1064  12.251721\n",
       "165   1065   6.459482\n",
       "166   1066   6.946973\n",
       "167   1067   6.740551\n",
       "168   1068   6.898499\n",
       "\n",
       "[169 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissionDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74060544",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissionDf.to_csv('final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901f7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d27c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f62de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
